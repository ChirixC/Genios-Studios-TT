{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>name</th>\n",
       "      <th>id_user</th>\n",
       "      <th>username</th>\n",
       "      <th>id_post</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>user_link</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>reply_screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>owner</th>\n",
       "      <th>shortcode</th>\n",
       "      <th>hour</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>clean_message_noemo</th>\n",
       "      <th>emojis_in_message</th>\n",
       "      <th>sentiment_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d415fe24f17c7a0a38762a</td>\n",
       "      <td>Lo que tiene que hacer el Miss Venezuela  es r...</td>\n",
       "      <td>Lisette Diaz</td>\n",
       "      <td>marazul41</td>\n",
       "      <td>marazul41</td>\n",
       "      <td>718139826350485</td>\n",
       "      <td>http://www.facebook.com/MissVenezuelaOficial/p...</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>http://www.facebook.com/marazul41</td>\n",
       "      <td>S√°bado</td>\n",
       "      <td>...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>MissVenezuelaOficial</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>hacer miss venezuela retirarse miss uni se√±al ...</td>\n",
       "      <td>hacer miss venezuela retirarse miss uni se√±al ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63d415fe24f17c7a0a38762b</td>\n",
       "      <td>Me imagino que dentro del plan de acci√≥n est√° ...</td>\n",
       "      <td>Kendra P√©rez</td>\n",
       "      <td>kendra.pereztabares</td>\n",
       "      <td>kendra.pereztabares</td>\n",
       "      <td>718139826350485</td>\n",
       "      <td>http://www.facebook.com/MissVenezuelaOficial/p...</td>\n",
       "      <td>2023-01-14</td>\n",
       "      <td>http://www.facebook.com/kendra.pereztabares</td>\n",
       "      <td>S√°bado</td>\n",
       "      <td>...</td>\n",
       "      <td>negativo</td>\n",
       "      <td>MissVenezuelaOficial</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>imagino dentro plan acci√≥n tener sistema votac...</td>\n",
       "      <td>imagino dentro plan acci√≥n tener sistema votac...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  63d415fe24f17c7a0a38762a   \n",
       "1  63d415fe24f17c7a0a38762b   \n",
       "\n",
       "                                             message           name  \\\n",
       "0  Lo que tiene que hacer el Miss Venezuela  es r...  Lisette Diaz    \n",
       "1  Me imagino que dentro del plan de acci√≥n est√° ...  Kendra P√©rez    \n",
       "\n",
       "               id_user             username          id_post  \\\n",
       "0            marazul41            marazul41  718139826350485   \n",
       "1  kendra.pereztabares  kendra.pereztabares  718139826350485   \n",
       "\n",
       "                                                link        date  \\\n",
       "0  http://www.facebook.com/MissVenezuelaOficial/p...  2023-01-14   \n",
       "1  http://www.facebook.com/MissVenezuelaOficial/p...  2023-01-14   \n",
       "\n",
       "                                     user_link weekday  ...  sentiment  \\\n",
       "0            http://www.facebook.com/marazul41  S√°bado  ...   negativo   \n",
       "1  http://www.facebook.com/kendra.pereztabares  S√°bado  ...   negativo   \n",
       "\n",
       "      reply_screen_name created_at  owner shortcode      hour  \\\n",
       "0  MissVenezuelaOficial        0.0      0         0  00:00:00   \n",
       "1  MissVenezuelaOficial        0.0      0         0  00:00:00   \n",
       "\n",
       "                                       clean_message  \\\n",
       "0  hacer miss venezuela retirarse miss uni se√±al ...   \n",
       "1  imagino dentro plan acci√≥n tener sistema votac...   \n",
       "\n",
       "                                 clean_message_noemo emojis_in_message  \\\n",
       "0  hacer miss venezuela retirarse miss uni se√±al ...                 0   \n",
       "1  imagino dentro plan acci√≥n tener sistema votac...                 0   \n",
       "\n",
       "   sentiment_code  \n",
       "0              -1  \n",
       "1              -1  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "\n",
    "file = '..\\\\data\\\\dataSocialMediaClean.csv'\n",
    "df = pd.read_csv(file, delimiter='\\t', engine='python', header=0, index_col=0)\n",
    "df.head(2) # Display the first 2 rows of the DataFrame to verify the correct load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>sentiment_code_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15316</th>\n",
       "      <td>63d415fe24f17c7a0a38b1fe</td>\n",
       "      <td>üòçüòçüòçüòçüòçüòçüòç</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>63d415fe24f17c7a0a388f21</td>\n",
       "      <td>siempre miss universo ‚ù§‚ù§</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5946</th>\n",
       "      <td>63d415fe24f17c7a0a388d64</td>\n",
       "      <td>ganadora</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>63d415fe24f17c7a0a38ad5a</td>\n",
       "      <td>amada amamos reina excelente trabajo üòç</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17218</th>\n",
       "      <td>63d415fe24f17c7a0a38b96c</td>\n",
       "      <td>robaron corona reina üò¢</td>\n",
       "      <td>negativo</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11039</th>\n",
       "      <td>63d415fe24f17c7a0a38a149</td>\n",
       "      <td>mano feeeeee ‚ù§</td>\n",
       "      <td>neutro</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>63d415fe24f17c7a0a387da0</td>\n",
       "      <td>reinaaa ‚ù§‚ù§</td>\n",
       "      <td>neutro</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7646</th>\n",
       "      <td>63d415fe24f17c7a0a389408</td>\n",
       "      <td>amanda ‚ù§</td>\n",
       "      <td>neutro</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15119</th>\n",
       "      <td>63d415fe24f17c7a0a38b139</td>\n",
       "      <td>nervios punta dios ‚ù§‚ù§‚ù§üî•üî•üî•üî•üî•</td>\n",
       "      <td>negativo</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20094</th>\n",
       "      <td>63d415fe24f17c7a0a38c4a8</td>\n",
       "      <td>miss universoo</td>\n",
       "      <td>positivo</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                           clean_message  \\\n",
       "15316  63d415fe24f17c7a0a38b1fe                                 üòçüòçüòçüòçüòçüòçüòç   \n",
       "6391   63d415fe24f17c7a0a388f21                siempre miss universo ‚ù§‚ù§   \n",
       "5946   63d415fe24f17c7a0a388d64                               ganadora    \n",
       "14128  63d415fe24f17c7a0a38ad5a  amada amamos reina excelente trabajo üòç   \n",
       "17218  63d415fe24f17c7a0a38b96c                  robaron corona reina üò¢   \n",
       "...                         ...                                     ...   \n",
       "11039  63d415fe24f17c7a0a38a149                          mano feeeeee ‚ù§   \n",
       "1910   63d415fe24f17c7a0a387da0                              reinaaa ‚ù§‚ù§   \n",
       "7646   63d415fe24f17c7a0a389408                                amanda ‚ù§   \n",
       "15119  63d415fe24f17c7a0a38b139             nervios punta dios ‚ù§‚ù§‚ù§üî•üî•üî•üî•üî•   \n",
       "20094  63d415fe24f17c7a0a38c4a8                         miss universoo    \n",
       "\n",
       "      sentiment  sentiment_code  sentiment_code_new  \n",
       "15316  positivo               1                   2  \n",
       "6391   positivo               1                   2  \n",
       "5946   positivo               1                   2  \n",
       "14128  positivo               1                   2  \n",
       "17218  negativo              -1                   0  \n",
       "...         ...             ...                 ...  \n",
       "11039    neutro               0                   1  \n",
       "1910     neutro               0                   1  \n",
       "7646     neutro               0                   1  \n",
       "15119  negativo              -1                   0  \n",
       "20094  positivo               1                   2  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the DataFrame to manipulate the data\n",
    "df2 = df.copy()\n",
    "\n",
    "# Select only the necessary columns\n",
    "cols = ['id', 'clean_message','sentiment','sentiment_code']\n",
    "df2 = df2[cols]\n",
    "\n",
    "# Remap sentiment codes to new values: -1 -> 0, 0 -> 1, 1 -> 2\n",
    "df2['sentiment_code_new'] = df2['sentiment_code'].map({\n",
    "    -1: 0,\n",
    "    0:  1,\n",
    "    1:  2\n",
    "})\n",
    "\n",
    "# Select a random subset of 1000 rows for training and testing the model\n",
    "df_subset = df2.sample(n=1000, random_state=42)\n",
    "df_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(df_subset['clean_message'].values, # Training and test texts\n",
    "                                                                    df_subset['sentiment_code_new'].values, # Training and test label \n",
    "                                                                    test_size=0.2, # 20% of the data for testing\n",
    "                                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BETO (BERT for Spanish) tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the training and test texts\n",
    "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test datasets\n",
    "train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']), # Input IDs of the tokens\n",
    "                              torch.tensor(train_encodings['attention_mask']), # Attention masks\n",
    "                              torch.tensor(train_labels)) # Training labels\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(test_encodings['input_ids']), # Input IDs of the tokens\n",
    "                             torch.tensor(test_encodings['attention_mask']), # Attention masks\n",
    "                             torch.tensor(test_labels)) # Test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pre-trained BERT model for sequence classification in Spanish\n",
    "model = BertForSequenceClassification.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased',\n",
    "                                                      num_labels=3)  #3 classes: positive|2, negative|0, neutral|1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a GPU is available and move the model to the GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "Accuracy: 0.7600, Precision: 0.6609, Recall: 0.7600, F1-score: 0.7065\n",
      "Confusion Matrix:\n",
      "[[ 18   0  12]\n",
      " [  3   0  23]\n",
      " [  9   1 134]]\n",
      "Epoch 2:\n",
      "Accuracy: 0.8150, Precision: 0.8243, Recall: 0.8150, F1-score: 0.8124\n",
      "Confusion Matrix:\n",
      "[[ 15   8   7]\n",
      " [  1  15  10]\n",
      " [  2   9 133]]\n",
      "Epoch 3:\n",
      "Accuracy: 0.7750, Precision: 0.7605, Recall: 0.7750, F1-score: 0.7599\n",
      "Confusion Matrix:\n",
      "[[ 21   3   6]\n",
      " [  3   6  17]\n",
      " [ 13   3 128]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Funci√≥n de p√©rdida\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the given dataloader.\n",
    "\n",
    "    Args:\n",
    "        model: The BERT model for sequence classification.\n",
    "        dataloader: DataLoader containing the data to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        accuracy: Accuracy of the model on the dataloader.\n",
    "        precision: Precision of the model on the dataloader.\n",
    "        recall: Recall of the model on the dataloader.\n",
    "        f1: F1-score of the model on the dataloader.\n",
    "        cm: Confusion matrix of the model on the dataloader.\n",
    "    \"\"\"\n",
    "    model.eval()        # Set the model to evaluation mode\n",
    "    all_labels = []     # List to store true labels\n",
    "    all_preds = []      # List to store model predictions\n",
    "    with torch.no_grad(): # Disable gradient calculation\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask, labels = [t.to(device) for t in batch] # Move data to GPU\n",
    "            outputs = model(input_ids, attention_mask=attention_mask) # Make predictions\n",
    "            _, preds = torch.max(outputs.logits, dim=1)  # Get the predictions with the highest probability\n",
    "            all_labels.extend(labels.cpu().numpy()) # Store true labels\n",
    "            all_preds.extend(preds.cpu().numpy()) # Store predictions\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, cm\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # Set the model to training mode\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = [t.to(device) for t in batch] # Move data to GPU\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels) # Make predictions\n",
    "        loss = outputs.loss # Calculate the loss\n",
    "        loss.backward() # Perform backpropagation\n",
    "        optimizer.step() # Update model parameters\n",
    "        optimizer.zero_grad() # Reset gradients\n",
    "    \n",
    "    # Evaluate on the test set after each epoch\n",
    "    accuracy, precision, recall, f1, cm = evaluate(model, test_loader)\n",
    "    print(f'Epoch {epoch + 1}:')\n",
    "    print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7750\n",
      "Precision: 0.7605\n",
      "Recall: 0.7750\n",
      "F1-score: 0.7599\n",
      "Confusion Matrix:\n",
      "[[ 21   3   6]\n",
      " [  3   6  17]\n",
      " [ 13   3 128]]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model on the test set\n",
    "accuracy, precision, recall, f1, cm = evaluate(model, test_loader)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'Confusion Matrix:\\n{cm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary and Recommendations**  \n",
    "- Model Performance: The model shows good accuracy, but there is room for improvement in precision and recall, especially for the neutral class.\n",
    "\n",
    "- Class Imbalance: The confusion matrices suggest possible class imbalance, with the model performing significantly better on the positive class.\n",
    "\n",
    "- Overfitting: The decrease in performance from epoch 2 to epoch 3 could indicate overfitting. Monitoring validation loss and implementing early stopping could help mitigate this.\n",
    "\n",
    "- Hyperparameter Tuning: We should experiment with different learning rates, batch sizes, and epochs to find the optimal settings for the dataset.\n",
    "\n",
    "- Data Augmentation: Increase the dataset size with data augmentation techniques or by collecting more labeled data to improve model robustness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
